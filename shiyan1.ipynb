{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5c3262",
   "metadata": {},
   "source": [
    "# 汽车里程数回归预测实验\n",
    "\n",
    "本实验以开源的auto-mpg数据集为基础，基于MindSpore深度学习库应用全连接神经网络进行汽车里程数预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5e896",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "\n",
    "- 掌握全连接神经网络的原理。\n",
    "- 了解如何使用MindSpore进行简单的回归模型的训练。\n",
    "- 了解如何使用MindSpore进行简单的回归模型的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94bde1",
   "metadata": {},
   "source": [
    "## 2、全连接神经网络的原理介绍\n",
    "\n",
    "浅层神经网络相比单层网络的差别在于隐藏层有多个神经节点，这就使得其可以处理“多输入多输出”的复杂问题。每一层的每一个节点都与上下层节点全部连接，这种神经网络称作全连接网络。\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef050b",
   "metadata": {},
   "source": [
    "### 2.1 正向传播\n",
    "\n",
    "$$z^{[1]} = \\left\\lgroup\\begin{matrix}z_{1}^{[1]} \\cr z_{2}^{[2]} \\cr z_{3}^{[3]}\\end{matrix}\\right\\rgroup = \\left\\lgroup\\begin{matrix}w_{1}^{[1]T}\\cdot x + b_{1}^{[1]} \\cr w_{2}^{[2]T}\\cdot x + b_{2}^{[2]} \\cr w_{3}^{[3]T}\\cdot x + b_{3}^{[3]}\\end{matrix}\\right\\rgroup = \\left\\lgroup\\begin{matrix}w_{1}^{[1]T}\\cdot x \\cr w_{2}^{[2]T}\\cdot x \\cr w_{3}^{[3]T}\\cdot x  \\end{matrix}\\right\\rgroup + b^{[1]} = W^{[1]}X + b^{[1]}$$\n",
    "\n",
    "\n",
    "\n",
    "$$a^{[1]} = \\left\\lgroup\\begin{matrix}a_{1}^{[1]} \\cr a_{2}^{[2]} \\cr a_{3}^{[3]}\\end{matrix}\\right\\rgroup = \\left\\lgroup\\begin{matrix}t\\left(z_{1}^{[1]}\\right) \\cr t\\left(z_{2}^{[2]}\\right) \\cr t\\left(z_{3}^{[3]}\\right)\\end{matrix}\\right\\rgroup = t\\left\\lgroup\\begin{matrix}\\left(z_{1}^{[1]}\\right) \\cr \\left(z_{2}^{[2]}\\right) \\cr \\left(z_{3}^{[3]}\\right) \\end{matrix}\\right\\rgroup = t\\left(z^{[1]}\\right)$$\n",
    "\n",
    "- 上角标中括号用于区分不同层\n",
    "- 下角标数字表示神经元节点的映射关系\n",
    "- 一个神经元节点包含上一层节点数$w$和$b$和下一层节点数$z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b6b5",
   "metadata": {},
   "source": [
    "### 2.2 反向传播\n",
    "\n",
    "梯度下降法：\n",
    "\n",
    "$$W = W - \\alpha  \\frac{\\partial L}{\\partial W}$$\n",
    "$$b = b - \\alpha  \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "式中$W$和$b$为模型的权重参数，$L$为模型定义的损失函数，$\\alpha$为超参数学习率；以上两式可以理解为：通过损失函数$L$对权重参数$W$和$b$进行求取导数，并利用导数乘以学习率对原来的$W$和$b$进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b5b24",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "\n",
    "- MindSpore 2.0（MindSpore版本会定期更新，本指导也会定期刷新，与版本配套）；\n",
    "- 本案例支持win_x86和Linux系统，CPU/Ascend均可运行。\n",
    "- 如果在本地运行此实验，请参考《MindSpore环境搭建实验手册》在本地安装MindSpore。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a016da",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26ecd4",
   "metadata": {},
   "source": [
    "### 4.1数据准备\n",
    "\n",
    "这个数据集来自卡内基梅隆大学维护的StatLib库。1983年美国统计协会博览会使用了该数据集。这个数据集是对StatLib库中提供的数据集稍加修改的版本。根据Ross Quinlan(1993)在预测属性“mpg”中的使用，删除了 8 个原始实例，因为它们的“mpg”属性值未知。原始数据集在“auto-mpg.data-original”文件中。\n",
    "\n",
    "该数据集共计9个特征，398个样本，用于回归任务。\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935439b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ascend-professional-construction-dataset.obs.cn-north-4.myhuaweicloud.com:443/deep-learning/auto-mpg.zip (7 kB)\n",
      "\n",
      "file_sizes: 100%|███████████████████████████| 6.68k/6.68k [00:00<00:00, 745kB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "\n",
    "# 下载汽车里程auto-mpg数据集\n",
    "url = \" https://ascend-professional-construction-dataset.obs.cn-north-4.myhuaweicloud.com:443/deep-learning/auto-mpg.zip\"  \n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d4565",
   "metadata": {},
   "source": [
    "### 4.2数据加载\n",
    "\n",
    "- 导入模型库：\n",
    "\n",
    "os模块主要用于对系统路径和文件进行处理。Numpy模块主要用于数据的基本运算操作。Matplotlib模块主要用于画图。MindSpore相关模块主要用于搭建网络、调用优化器、读取数据集和将数据集处理成网络的标准输入格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相关依赖库\n",
    "import  os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd  #版本采用1.3.0\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "import mindspore.dataset.transforms as C\n",
    "import mindspore.dataset.vision as CV\n",
    "\n",
    "from mindspore import nn, Tensor, ops\n",
    "from mindspore.train import Model\n",
    "from mindspore.train import Accuracy, MAE, MSE\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore.train import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target='CPU')  # device_target支持\"Ascend\"、\"CPU\"。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040fecec",
   "metadata": {},
   "source": [
    "- 查看数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['25.0   4   110.0      87.00      2672.      17.5   70  2\\t\"peugeot 504\"'], ['24.0   4   107.0      90.00      2430.      14.5   70  2\\t\"audi 100 ls\"'], ['25.0   4   104.0      95.00      2375.      17.5   70  2\\t\"saab 99e\"'], ['26.0   4   121.0      113.0      2234.      12.5   70  2\\t\"bmw 2002\"'], ['21.0   6   199.0      90.00      2648.      15.0   70  1\\t\"amc gremlin\"'], ['10.0   8   360.0      215.0      4615.      14.0   70  1\\t\"ford f250\"'], ['10.0   8   307.0      200.0      4376.      15.0   70  1\\t\"chevy c20\"'], ['11.0   8   318.0      210.0      4382.      13.5   70  1\\t\"dodge d200\"'], ['9.0    8   304.0      193.0      4732.      18.5   70  1\\t\"hi 1200d\"'], ['27.0   4   97.00      88.00      2130.      14.5   71  3\\t\"datsun pl510\"'], ['28.0   4   140.0      90.00      2264.      15.5   71  1\\t\"chevrolet vega 2300\"'], ['25.0   4   113.0      95.00      2228.      14.0   71  3\\t\"toyota corona\"'], ['25.0   4   98.00      ?          2046.      19.0   71  1\\t\"ford pinto\"'], ['19.0   6   232.0      100.0      2634.      13.0   71  1\\t\"amc gremlin\"'], ['16.0   6   225.0      105.0      3439.      15.5   71  1\\t\"plymouth satellite custom\"'], ['17.0   6   250.0      100.0      3329.      15.5   71  1\\t\"chevrolet chevelle malibu\"'], ['19.0   6   250.0      88.00      3302.      15.5   71  1\\t\"ford torino 500\"'], ['18.0   6   232.0      100.0      3288.      15.5   71  1\\t\"amc matador\"'], ['14.0   8   350.0      165.0      4209.      12.0   71  1\\t\"chevrolet impala\"'], ['14.0   8   400.0      175.0      4464.      11.5   71  1\\t\"pontiac catalina brougham\"']]\n"
     ]
    }
   ],
   "source": [
    "#加载数据集\n",
    "with open('./auto-mpg.data') as csv_file:\n",
    "    data = list(csv.reader(csv_file, delimiter=','))\n",
    "print(data[20:40]) # 打印部分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5216bb",
   "metadata": {},
   "source": [
    "- 利用pandas模块读取数据\n",
    "\n",
    "Pandas模块是一个处理表格类数据非常有效的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51129c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#使用pandas读取数据\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "#遇到？换成nan，忽略\\t之后的内容，已空格作为分隔符。\n",
    "raw_data = pd.read_csv('./auto-mpg.data', names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "data = raw_data.copy()\n",
    "\n",
    "#查看数据形状\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2050c11",
   "metadata": {},
   "source": [
    "- 数据预处理\n",
    "\n",
    "对于数据集中的空值，我们要在建模前进行处理。此处空值的数据较少，我们直接进行删除。特征Origin代表着车辆的归属区域信息，此处总共分为三种，欧洲，美国，日本，我们需要对此特征进行one-hot编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于数据集中的空值，我们要在建模前进行处理。此处空值的数据较少，我们直接进行删除。\n",
    "#清洗空数据\n",
    "data = data.dropna()\n",
    "data.tail()\n",
    "#Pandas库提供了简单的数据集统计信息，我们可直接调用函数describe()进行查看。\n",
    "#查看训练数据集的结构\n",
    "origin = data.pop('Origin')\n",
    "data_labels = data.pop('MPG')\n",
    "train_stats = data.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats\n",
    "#归一化数据\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_data = norm(data)\n",
    "# 将MPG放回归一化后的数据中\n",
    "normed_data['MPG'] = data_labels\n",
    "# 离散特征处理\n",
    "# 特征Origin代表着车辆的归属区域信息，此处总共分为三种，欧洲，美国，日本，我们需要对此特征进行one-hot编码。\n",
    "# 对origin属性进行one-hot编码\n",
    "normed_data['USA'] = (origin == 1)*1.0\n",
    "normed_data['Europe'] = (origin == 2)*1.0\n",
    "normed_data['Japan'] = (origin == 3)*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07c0af",
   "metadata": {},
   "source": [
    "模型训练需要区分特征值与目标值，也就是我们常说的X值与Y值，此处MPG为Y值，其余的特征为X值。\n",
    "\n",
    "在模型构建的时候，我们一般需要准备两份数据，一份训练集数据用于模型的训练构建，一份测试集用于模型的评估优化。创建比例0.8，用于分割训练集和验证集，80%的数据用于模型训练，20%的数据用于模型验证。并把数据集处理成模型所需的数据格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d053933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据x尺寸： (314, 9)\n",
      "训练数据y尺寸： (314,)\n",
      "测试数据x尺寸： (78, 9)\n",
      "测试数据y尺寸： (78,)\n"
     ]
    }
   ],
   "source": [
    "#将数据集按照4：1划分成训练集和测试集\n",
    "train_dataset = normed_data.sample(frac=0.8,random_state=0)\n",
    "test_dataset = normed_data.drop(train_dataset.index)\n",
    "\n",
    "#模型训练需要区分特征值与目标值，也就是我们常说的X值与Y值，此处MPG为Y值，其余的特征为X值。\n",
    "#将目标值和特征分开\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "X_train, Y_train = np.array(train_dataset, dtype=np.float32), np.array(train_labels, dtype=np.float32)\n",
    "X_test, Y_test = np.array(test_dataset, dtype=np.float32), np.array(test_labels, dtype=np.float32)\n",
    "\n",
    "#查看数据集尺寸\n",
    "print('训练数据x尺寸：',X_train.shape)\n",
    "print('训练数据y尺寸：',Y_train.shape)\n",
    "print('测试数据x尺寸：',X_test.shape)\n",
    "print('测试数据y尺寸：',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterable object as input source\n",
    "class Iterable:\n",
    "    def __init__(self, X, Y):\n",
    "        self._data = X\n",
    "        self._label = Y[:, np.newaxis]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._data[index], self._label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "data = Iterable(X_train, Y_train)\n",
    "dataset_train = GeneratorDataset(source=data, column_names=[\"data\", \"label\"])\n",
    "data = Iterable(X_test, Y_test)\n",
    "dataset_test = GeneratorDataset(source=data, column_names=[\"data\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3593f",
   "metadata": {},
   "source": [
    "## 5、模型构建\n",
    "\n",
    "汽车油耗里程数据集准备完成，接下来我们就需要构建训练模型，本实验采用的是全连接神经网络算法，所以我们首先需要建立初始化的神经网络。nn.cell能够用来组成网络模型;模型共包含3个全连接，采用Relu当做激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "class Regression_car(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Regression_car, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Dense(9,64, activation='relu')\n",
    "        self.fc2 = nn.Dense(64,64, activation='relu')\n",
    "        self.fc3 = nn.Dense(64,1)\n",
    "        \n",
    "        \n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cb15e",
   "metadata": {},
   "source": [
    "## 6、模型训练与测试\n",
    "\n",
    "指定模型所需的损失函数、评估指标、优化器等参数。回归问题，损失函数采用均方误差MSE。将创建好的网络、损失函数、评估指标、优化器等参数装入模型中对模型进行训练。需要逐步打印出MAE、MSE的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 400.001221  [  0/314]\n",
      "loss: 224.835861  [100/314]\n",
      "loss: 36.852665  [200/314]\n",
      "loss: 10.433537  [300/314]\n",
      " Avg loss: 15.366340 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 78.916695  [  0/314]\n",
      "loss: 92.176308  [100/314]\n",
      "loss: 1.867100  [200/314]\n",
      "loss: 0.489709  [300/314]\n",
      " Avg loss: 8.757651 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 8.841584  [  0/314]\n",
      "loss: 53.447109  [100/314]\n",
      "loss: 6.799405  [200/314]\n",
      "loss: 182.811768  [300/314]\n",
      " Avg loss: 9.886613 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.432492  [  0/314]\n",
      "loss: 0.008578  [100/314]\n",
      "loss: 1.231788  [200/314]\n",
      "loss: 0.000276  [300/314]\n",
      " Avg loss: 7.996487 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.316351  [  0/314]\n",
      "loss: 3.636306  [100/314]\n",
      "loss: 34.566517  [200/314]\n",
      "loss: 1.199968  [300/314]\n",
      " Avg loss: 7.481086 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.954388  [  0/314]\n",
      "loss: 3.801863  [100/314]\n",
      "loss: 0.069054  [200/314]\n",
      "loss: 7.224389  [300/314]\n",
      " Avg loss: 9.153750 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 20.199562  [  0/314]\n",
      "loss: 0.208017  [100/314]\n",
      "loss: 0.790782  [200/314]\n",
      "loss: 15.037037  [300/314]\n",
      " Avg loss: 7.700409 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 6.698353  [  0/314]\n",
      "loss: 0.081810  [100/314]\n",
      "loss: 2.738175  [200/314]\n",
      "loss: 11.217800  [300/314]\n",
      " Avg loss: 8.029077 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 8.190888  [  0/314]\n",
      "loss: 1.183087  [100/314]\n",
      "loss: 0.564367  [200/314]\n",
      "loss: 0.254291  [300/314]\n",
      " Avg loss: 8.502394 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 13.248707  [  0/314]\n",
      "loss: 11.148455  [100/314]\n",
      "loss: 1.246378  [200/314]\n",
      "loss: 0.138619  [300/314]\n",
      " Avg loss: 7.397330 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#定义网络，损失函数，评估指标  优化器\n",
    "network = Regression_car()\n",
    "net_loss = nn.MSELoss()\n",
    "net_opt = nn.RMSProp(network.trainable_params(), 0.001)\n",
    "\n",
    "# 定义用于训练的train_loop函数。\n",
    "def train_loop(model, dataset, loss_fn, optimizer):\n",
    "    # 定义正向计算函数\n",
    "    def forward_fn(data, label):\n",
    "        logits = model(data)\n",
    "        loss = loss_fn(logits, label)\n",
    "        return loss\n",
    "\n",
    "    # 定义微分函数，使用mindspore.value_and_grad获得微分函数grad_fn,输出loss和梯度。\n",
    "    # 由于是对模型参数求导,grad_position 配置为None，传入可训练参数。\n",
    "    grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "    # 定义 one-step training函数\n",
    "    def train_step(data, label):\n",
    "        loss, grads = grad_fn(data, label)\n",
    "        optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "    size = dataset.get_dataset_size()\n",
    "    model.set_train()\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        data, label = ms.Tensor(data[:, np.newaxis].T, ms.float32), ms.Tensor(label[:, np.newaxis], ms.float32)\n",
    "        loss = train_step(data, label)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "\n",
    "# 定义用于测试的test_loop函数。\n",
    "def test_loop(model, dataset, loss_fn):\n",
    "    num_batches = dataset.get_dataset_size()\n",
    "    model.set_train(False)\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for data, label in dataset.create_tuple_iterator():\n",
    "        data, label = ms.Tensor(data[:, np.newaxis].T, ms.float32), ms.Tensor(label[:, np.newaxis], ms.float32)\n",
    "        pred = model(data)\n",
    "        total += len(data)\n",
    "        test_loss += loss_fn(pred, label).asnumpy()\n",
    "        correct += (pred.argmax(1) == label).asnumpy().sum()\n",
    "    test_loss /= num_batches\n",
    "    correct /= total\n",
    "    print(f\" Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(network, dataset_train, net_loss, net_opt)\n",
    "    test_loop(network, dataset_test, net_loss)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
